{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb49f83-8678-4bcb-ad08-4e39e258e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a MobileNetV3 Model as defined in:\n",
    "Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam. (2019).\n",
    "Searching for MobileNetV3\n",
    "arXiv preprint arXiv:1905.02244.\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "__all__ = ['mobilenetv3_large', 'mobilenetv3_small']\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, _make_divisible(channel // reduction, 8)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(_make_divisible(channel // reduction, 8), channel),\n",
    "                h_sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8892c0-806b-4134-947e-609c4a2092b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_3x3(inp, oup, stride, batch_norm = True):\n",
    "    layers = [\n",
    "        nn.Conv2d(inp, oup, kernel_size=3, stride=1,\n",
    "                  padding=1, bias=False),\n",
    "        h_swish()\n",
    "    ]#\n",
    "    if batch_norm:\n",
    "        layers.insert(1, nn.BatchNorm2d(oup))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv_1x1(inp, oup, batch_norm = True):\n",
    "    layers = [\n",
    "        nn.Conv2d(inp, oup, kernel_size=1, stride=1,\n",
    "                  padding=0, bias=False),\n",
    "        h_swish()\n",
    "    ]\n",
    "    if batch_norm:\n",
    "        layers.insert(1, nn.BatchNorm2d(oup))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8affe328-a0e9-4cb8-93b9-c105c3567bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def od_conv_1x1(inp, oup, stride = 1, kernel_num = 4,\n",
    "                temperature = 60,\n",
    "                batch_norm = True):\n",
    "    return nn.Sequential(\n",
    "        ODConvBN(inp, oup, kernel_size = 1, stride = stride,\n",
    "            kernel_num = kernel_num, temperature = temperature) \\\n",
    "                if batch_norm == True else \\\n",
    "        ODConv2d(inp, oup, kernel_size = 1, stride = stride,\n",
    "            kernel_num = kernel_num, temperature = temperature),\n",
    "\n",
    "        h_swish()\n",
    "    )\n",
    "\n",
    "def od_conv_3x3(inp, oup, stride = 1,\n",
    "                kernel_num = 4, temperature = 60,\n",
    "                batch_norm = True):\n",
    "    return nn.Sequential(\n",
    "         ODConvBN(inp, oup, kernel_size = 3, stride = stride,\n",
    "            kernel_num = kernel_num, temperature = temperature) \\\n",
    "                if batch_norm == True else \\\n",
    "        ODConv2d(inp, oup, kernel_size = 3, stride = stride,\n",
    "            kernel_num = kernel_num, temperature = temperature),\n",
    "\n",
    "        h_swish()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6936ef6d-ce0d-4865-9ba8-fc465768c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidualOD(nn.Module):\n",
    "    def __init__(self, inp, hidden_dim, oup, kernel_size,\n",
    "                 stride, use_se, use_hs,\n",
    "                 kernel_num = 4, temperature = 60.0):\n",
    "        super(InvertedResidualOD, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "        print(\"Using OmniDimensional\")\n",
    "        if inp == hidden_dim:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                ODConvBN(hidden_dim, hidden_dim, kernel_size, stride,\n",
    "                         groups=hidden_dim, kernel_num = kernel_num,\n",
    "                         temperature = temperature),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                # pw-linear\n",
    "                ODConv2d(hidden_dim, oup, 1, 1, kernel_num = kernel_num,\n",
    "                         temperature = temperature),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                ODConvBN(inp, hidden_dim, kernel_size = 1, stride = 1,\n",
    "                         kernel_num = kernel_num, temperature = temperature),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                ODConvBN(hidden_dim, hidden_dim, kernel_size,\n",
    "                         stride, groups=hidden_dim, kernel_num = kernel_num,\n",
    "                         temperature = temperature),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                ODConv2d(hidden_dim, oup, 1, 1, kernel_num = kernel_num,\n",
    "                         temperature = temperature),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, hidden_dim, oup, kernel_size, stride, use_se, use_hs):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        print(\"Using Normal\")\n",
    "        if inp == hidden_dim:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80af455-f7fb-4611-a3f9-77175748195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, cfgs, mode, kernel_num,\n",
    "                 temperature, od_bottleneck = 0, \n",
    "                 od_outside = 0, num_classes = 10, width_mult=1.,\n",
    "                 use_od = False, drop_rate = 0.2):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = cfgs\n",
    "        self.use_od = use_od\n",
    "        assert mode in ['large', 'small']\n",
    "\n",
    "        num_od = int(od_outside)\n",
    "        od_bottleneck = int(od_bottleneck)\n",
    "        \n",
    "        self.num_od = num_od\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(16 * width_mult, 8)\n",
    "\n",
    "        layers = []\n",
    "        if num_od > 0:\n",
    "            print(\"Using OD\")\n",
    "            layers.append(od_conv_3x3(3, input_channel, stride = 2,\n",
    "                                      kernel_num = kernel_num,\n",
    "                                      temperature = temperature))\n",
    "        else:\n",
    "            print(\"Using Normal\")\n",
    "            layers.append(conv_3x3(3, input_channel, stride = 2))\n",
    "        \n",
    "        # building inverted residual blocks\n",
    "        \n",
    "\n",
    "        i = 0\n",
    "        for k, t, c, use_se, use_hs, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            exp_size = _make_divisible(input_channel * t, 8)\n",
    "            block = InvertedResidual if (use_od == False or i >= od_bottleneck) \\\n",
    "                        else InvertedResidualOD\n",
    "            \n",
    "            if use_od == False or i >= od_bottleneck:\n",
    "                layers.append(block(input_channel, exp_size, output_channel,\n",
    "                                    k, s, use_se, use_hs))\n",
    "            else:\n",
    "                layers.append(block(input_channel, exp_size, output_channel,\n",
    "                                    k, s, use_se, use_hs, kernel_num = kernel_num,\n",
    "                                    temperature = temperature))\n",
    "                i += 1\n",
    "            \n",
    "            input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # building last several layers\n",
    "        if num_od >= 2:\n",
    "            print(\"Using OD\")\n",
    "            self.conv = od_conv_1x1(input_channel, exp_size,\n",
    "                                    kernel_num = kernel_num,\n",
    "                                    temperature = temperature)\n",
    "        else:\n",
    "            print(\"Using Normal\")\n",
    "            self.conv = conv_1x1(input_channel, exp_size)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        output_channel = {'large': 1280, 'small': 1024}\n",
    "\n",
    "        output_channel = _make_divisible(output_channel[mode] * width_mult, 8) if width_mult > 1.0 else output_channel[mode]\n",
    "\n",
    "        omni_layers = []\n",
    "        not_omni_layers = []\n",
    "        temp_od = num_od - 2\n",
    "\n",
    "        self.list_layers = []\n",
    "        for i in range(2):\n",
    "            if temp_od > 0:\n",
    "                self.list_layers.append(\"OD\")\n",
    "            else:\n",
    "                self.list_layers.append(\"Normal\")\n",
    "\n",
    "            temp_od -= 1\n",
    "\n",
    "\n",
    "        input_channel = exp_size\n",
    "        for layer in self.list_layers:\n",
    "            if layer == \"OD\":\n",
    "                print(\"Using OD\")\n",
    "                omni_layers.append(od_conv_1x1(input_channel, output_channel,\n",
    "                                          kernel_num = kernel_num,\n",
    "                                          temperature = temperature))\n",
    "            else:\n",
    "                print(\"Using Normal\")\n",
    "                not_omni_layers.append(nn.Linear(input_channel, output_channel))\n",
    "\n",
    "            input_channel = output_channel\n",
    "            output_channel = num_classes\n",
    "\n",
    "        self.omni_layers = nn.Sequential(*omni_layers)\n",
    "        self.normal_layers = nn.Sequential(*not_omni_layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.omni_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.normal_layers(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def net_update_temperature(self, temperature):\n",
    "        for modules in self.modules():\n",
    "            if hasattr(modules, \"update_temperature\"):\n",
    "                modules.update_temperature(temperature)\n",
    "\n",
    "    def display_temperature(self):\n",
    "        for modules in self.modules():\n",
    "            if hasattr(modules, \"get_temperature\"):\n",
    "                return modules.get_temperature()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da42216-a946-4e17-a99d-786ae43c4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenetv3_large(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Large model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k, t,   c,  SE, HS, s\n",
    "        [3,   1,  16, 0, 0, 1],\n",
    "        [3,   4,  24, 0, 0, 2],\n",
    "        [3,   3,  24, 0, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 2],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [3,   6,  80, 0, 1, 2],\n",
    "        [3, 2.5,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 2],\n",
    "        [5,   6, 160, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 1]\n",
    "    ]\n",
    "    return MobileNetV3(cfgs, mode='large', **kwargs)\n",
    "\n",
    "\n",
    "def mobilenetv3_small(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Small model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k,   t,  c, SE, HS, s\n",
    "        [3,    1,  16, 1, 0, 2],\n",
    "        [3,  4.5,  24, 0, 0, 2],\n",
    "        [3, 3.67,  24, 0, 0, 1],\n",
    "        [5,    4,  40, 1, 1, 2],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 2],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "    ]\n",
    "\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ab8ba8-7b86-4b56-9291-cc655cdbba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0ebbf6-4ede-4a88-bc21-ba54c4a33f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6d5f5-93dc-4131-823b-69759f8def1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 7241728/170498071 [02:45<1:32:36, 29379.81it/s]"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir, download = True):\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  train_data = datasets.CIFAR10(\n",
    "      root = data_dir, train = True,\n",
    "      download = download, transform = transform\n",
    "  )\n",
    "\n",
    "  test_data = datasets.CIFAR10(\n",
    "      root = data_dir, train = False,\n",
    "      download = download, transform = transform\n",
    "  )\n",
    "\n",
    "  return (train_data, test_data)\n",
    "\n",
    "train_data, test_data = load_data('./data/cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931d1a1-7b4c-4f75-90ca-339106afa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "args = Namespace(\n",
    "    data_dir = './data/cifar10',\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    batch_size = 128,\n",
    "    num_workers = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04853534-3ee6-4215-8d3d-c60b2379a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def check_logging_directory(path):\n",
    "  parent_directory = os.path.dirname(path)\n",
    "  if not os.path.exists(parent_directory):\n",
    "    os.makedirs(parent_directory)\n",
    "    print(\"Create new directory\")\n",
    "\n",
    "logging_path = './logging/bayesian_omni_cifar10.log'\n",
    "check_logging_directory(logging_path)\n",
    "\n",
    "logging.basicConfig(filename=logging_path, level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
