{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe99bc0-b98f-4f98-b57a-c10e4beaa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd\n",
    "from omni import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511f3d35-94a9-4e55-ab6d-318a4de53397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a MobileNetV3 Model as defined in:\n",
    "Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam. (2019).\n",
    "Searching for MobileNetV3\n",
    "arXiv preprint arXiv:1905.02244.\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "__all__ = ['mobilenetv3_large', 'mobilenetv3_small']\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, _make_divisible(channel // reduction, 8)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(_make_divisible(channel // reduction, 8), channel),\n",
    "                h_sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, kernel_size = 3, stride = stride,\n",
    "                            padding = 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        h_swish()\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, kernel_size = 1, stride = 1,\n",
    "                            padding = 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        h_swish()\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, hidden_dim, oup, kernel_size, stride, use_se, use_hs):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if inp == hidden_dim:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                ODConvBN(hidden_dim, hidden_dim, kernel_size, stride, groups=hidden_dim),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                # pw-linear\n",
    "                ODConv2d(hidden_dim, oup, 1, 1),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                ODConvBN(inp, hidden_dim, kernel_size = 1, stride = 1),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                ODConvBN(hidden_dim, hidden_dim, kernel_size, stride, groups=hidden_dim),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                ODConv2d(hidden_dim, oup, 1, 1),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, cfgs, mode, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = cfgs\n",
    "        assert mode in ['large', 'small']\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(16 * width_mult, 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for k, t, c, use_se, use_hs, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            exp_size = _make_divisible(input_channel * t, 8)\n",
    "            layers.append(block(input_channel, exp_size, output_channel, k, s, use_se, use_hs))\n",
    "            input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # building last several layers\n",
    "        self.conv = conv_1x1_bn(input_channel, exp_size)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        output_channel = {'large': 1280, 'small': 1024}\n",
    "\n",
    "        output_channel = _make_divisible(output_channel[mode] * width_mult, 8) if width_mult > 1.0 else output_channel[mode]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(exp_size, output_channel),\n",
    "            h_swish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(output_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def mobilenetv3_large(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Large model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k, t,   c,  SE, HS, s\n",
    "        [3,   1,  16, 0, 0, 1],\n",
    "        [3,   4,  24, 0, 0, 2],\n",
    "        [3,   3,  24, 0, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 2],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [3,   6,  80, 0, 1, 2],\n",
    "        [3, 2.5,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 2],\n",
    "        [5,   6, 160, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 1]\n",
    "    ]\n",
    "    return MobileNetV3(cfgs, mode='large', **kwargs)\n",
    "\n",
    "\n",
    "def mobilenetv3_small(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Small model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k,   t,  c, SE, HS, s\n",
    "        [3,    1,  16, 1, 0, 2],\n",
    "        [3,  4.5,  24, 0, 0, 2],\n",
    "        [3, 3.67,  24, 0, 0, 1],\n",
    "        [5,    4,  40, 1, 1, 2],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 2],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "    ]\n",
    "\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ade2bc-b3d5-4ad3-bf8e-96f3472d5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def69fa4-e356-43d1-af2e-e5889993a42c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2ae798-ceb6-4610-ba64-304aba3e1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7269b1e-25b6-4c82-a33f-b1f83dadff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir, download = True):\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  train_data = datasets.CIFAR10(\n",
    "      root = data_dir, train = True,\n",
    "      download = download, transform = transform\n",
    "  )\n",
    "\n",
    "  test_data = datasets.CIFAR10(\n",
    "      root = data_dir, train = False,\n",
    "      download = download, transform = transform\n",
    "  )\n",
    "\n",
    "  return (train_data, test_data)\n",
    "\n",
    "train_data, test_data = load_data('./data/cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6025fb9-496d-4820-ba81-dfe7cd7975f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size,\n",
    "                          shuffle = True, num_workers = num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size,\n",
    "                         shuffle = True, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2c6b43-6a2e-4230-8b6e-8575fd80788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6046ad77-f972-4ce6-970b-16c5ababca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, device, alpha = 1.0):\n",
    "  if alpha > 0:\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "  else:\n",
    "    lam = 1\n",
    "\n",
    "  batch_size = x.shape[0]\n",
    "  index_sample = torch.randperm(batch_size).to(device)\n",
    "\n",
    "  mixed_x = lam * x + (1 - lam) * x[index_sample, :]\n",
    "  y, y_sampled =  y, y[index_sample]\n",
    "\n",
    "  return mixed_x, y, y_sampled, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "  return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0982adb8-9ddd-47aa-8c2c-238bdcf0544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def check_logging_directory(path):\n",
    "  parent_directory = os.path.dirname(path)\n",
    "  if not os.path.exists(parent_directory):\n",
    "    os.makedirs(parent_directory)\n",
    "    print(\"Create new directory\")\n",
    "\n",
    "logging_path = './logging/mixup_mobilenetv3_omni.log'\n",
    "check_logging_directory(logging_path)\n",
    "\n",
    "logging.basicConfig(filename=logging_path, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa95a1d0-fe3c-4078-85d5-06439b7f793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2396571"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "mb_v3 =  mobilenetv3_small(num_classes = 10).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(mb_v3.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "\n",
    "count_parameters(mb_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded28beb-1775-4dd7-96fb-af835863e41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c45a45a1ee343f78623811d6494671a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4477c07621ec423e888c7b0d86f95bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dac5319c0e143128d58770d75dabba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training MobileNetV3 - Omni Dimensional Dynamic Convolution ðŸš€\n",
      "========================================\n",
      "\u001b[1;34mEpoch 1/100\u001b[0m\n",
      "Train Loss: 1.73\t|\tTrain Acc: 38.30%\n",
      "Val Loss: 1.44\t|\tVal Acc: 49.73%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 2/100\u001b[0m\n",
      "Train Loss: 1.37\t|\tTrain Acc: 55.28%\n",
      "Val Loss: 0.97\t|\tVal Acc: 66.96%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 3/100\u001b[0m\n",
      "Train Loss: 1.23\t|\tTrain Acc: 61.80%\n",
      "Val Loss: 0.84\t|\tVal Acc: 71.61%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 4/100\u001b[0m\n",
      "Train Loss: 1.13\t|\tTrain Acc: 65.92%\n",
      "Val Loss: 0.73\t|\tVal Acc: 77.24%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 5/100\u001b[0m\n",
      "Train Loss: 1.06\t|\tTrain Acc: 68.66%\n",
      "Val Loss: 0.68\t|\tVal Acc: 78.11%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 6/100\u001b[0m\n",
      "Train Loss: 1.01\t|\tTrain Acc: 70.57%\n",
      "Val Loss: 0.65\t|\tVal Acc: 80.26%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 7/100\u001b[0m\n",
      "Train Loss: 0.96\t|\tTrain Acc: 72.66%\n",
      "Val Loss: 0.60\t|\tVal Acc: 81.77%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 8/100\u001b[0m\n",
      "Train Loss: 0.96\t|\tTrain Acc: 72.51%\n",
      "Val Loss: 0.64\t|\tVal Acc: 80.23%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 9/100\u001b[0m\n",
      "Train Loss: 0.97\t|\tTrain Acc: 72.29%\n",
      "Val Loss: 0.65\t|\tVal Acc: 81.39%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 10/100\u001b[0m\n",
      "Train Loss: 0.91\t|\tTrain Acc: 73.92%\n",
      "Val Loss: 0.57\t|\tVal Acc: 82.98%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 11/100\u001b[0m\n",
      "Train Loss: 0.91\t|\tTrain Acc: 74.38%\n",
      "Val Loss: 0.62\t|\tVal Acc: 82.72%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 12/100\u001b[0m\n",
      "Train Loss: 0.86\t|\tTrain Acc: 75.61%\n",
      "Val Loss: 0.54\t|\tVal Acc: 84.21%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 14/100\u001b[0m\n",
      "Train Loss: 0.80\t|\tTrain Acc: 78.48%\n",
      "Val Loss: 0.50\t|\tVal Acc: 84.22%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 15/100\u001b[0m\n",
      "Train Loss: 0.76\t|\tTrain Acc: 78.74%\n",
      "Val Loss: 0.56\t|\tVal Acc: 84.23%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 16/100\u001b[0m\n",
      "Train Loss: 0.76\t|\tTrain Acc: 79.00%\n",
      "Val Loss: 0.53\t|\tVal Acc: 85.17%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 17/100\u001b[0m\n",
      "Train Loss: 0.78\t|\tTrain Acc: 78.26%\n",
      "Val Loss: 0.47\t|\tVal Acc: 85.67%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 18/100\u001b[0m\n",
      "Train Loss: 0.83\t|\tTrain Acc: 77.00%\n",
      "Val Loss: 0.50\t|\tVal Acc: 85.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\u001b[1;34mEpoch 23/100\u001b[0m\n",
      "Train Loss: 0.75\t|\tTrain Acc: 79.70%\n",
      "Val Loss: 0.57\t|\tVal Acc: 85.57%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 24/100\u001b[0m\n",
      "Train Loss: 0.76\t|\tTrain Acc: 79.33%\n",
      "Val Loss: 0.50\t|\tVal Acc: 85.65%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 25/100\u001b[0m\n",
      "Train Loss: 0.70\t|\tTrain Acc: 81.42%\n",
      "Val Loss: 0.52\t|\tVal Acc: 85.22%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 26/100\u001b[0m\n",
      "Train Loss: 0.69\t|\tTrain Acc: 81.44%\n",
      "Val Loss: 0.47\t|\tVal Acc: 86.58%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 27/100\u001b[0m\n",
      "Train Loss: 0.72\t|\tTrain Acc: 81.21%\n",
      "Val Loss: 0.51\t|\tVal Acc: 85.88%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 28/100\u001b[0m\n",
      "Train Loss: 0.74\t|\tTrain Acc: 79.54%\n",
      "Val Loss: 0.49\t|\tVal Acc: 86.48%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 29/100\u001b[0m\n",
      "Train Loss: 0.66\t|\tTrain Acc: 82.61%\n",
      "Val Loss: 0.48\t|\tVal Acc: 86.27%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 30/100\u001b[0m\n",
      "Train Loss: 0.73\t|\tTrain Acc: 80.00%\n",
      "Val Loss: 0.50\t|\tVal Acc: 85.83%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 31/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.79%\n",
      "Val Loss: 0.46\t|\tVal Acc: 87.12%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 32/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 81.01%\n",
      "Val Loss: 0.50\t|\tVal Acc: 86.25%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 33/100\u001b[0m\n",
      "Train Loss: 0.77\t|\tTrain Acc: 78.50%\n",
      "Val Loss: 0.51\t|\tVal Acc: 85.78%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 35/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.88%\n",
      "Val Loss: 0.47\t|\tVal Acc: 86.96%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 36/100\u001b[0m\n",
      "Train Loss: 0.75\t|\tTrain Acc: 79.22%\n",
      "Val Loss: 0.48\t|\tVal Acc: 86.72%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 37/100\u001b[0m\n",
      "Train Loss: 0.76\t|\tTrain Acc: 79.12%\n",
      "Val Loss: 0.57\t|\tVal Acc: 86.00%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 38/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.76%\n",
      "Val Loss: 0.56\t|\tVal Acc: 85.54%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 39/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.28%\n",
      "Val Loss: 0.48\t|\tVal Acc: 86.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\u001b[1;34mEpoch 55/100\u001b[0m\n",
      "Train Loss: 0.69\t|\tTrain Acc: 81.03%\n",
      "Val Loss: 0.45\t|\tVal Acc: 87.65%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 56/100\u001b[0m\n",
      "Train Loss: 0.67\t|\tTrain Acc: 82.16%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.53%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 57/100\u001b[0m\n",
      "Train Loss: 0.70\t|\tTrain Acc: 80.73%\n",
      "Val Loss: 0.46\t|\tVal Acc: 87.44%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 58/100\u001b[0m\n",
      "Train Loss: 0.62\t|\tTrain Acc: 83.58%\n",
      "Val Loss: 0.51\t|\tVal Acc: 86.95%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 59/100\u001b[0m\n",
      "Train Loss: 0.60\t|\tTrain Acc: 84.23%\n",
      "Val Loss: 0.49\t|\tVal Acc: 86.85%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 60/100\u001b[0m\n",
      "Train Loss: 0.68\t|\tTrain Acc: 81.75%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.10%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 61/100\u001b[0m\n",
      "Train Loss: 0.66\t|\tTrain Acc: 82.20%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.64%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 62/100\u001b[0m\n",
      "Train Loss: 0.65\t|\tTrain Acc: 82.77%\n",
      "Val Loss: 0.45\t|\tVal Acc: 87.77%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 63/100\u001b[0m\n",
      "Train Loss: 0.64\t|\tTrain Acc: 83.08%\n",
      "Val Loss: 0.46\t|\tVal Acc: 87.28%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 64/100\u001b[0m\n",
      "Train Loss: 0.67\t|\tTrain Acc: 81.30%\n",
      "Val Loss: 0.49\t|\tVal Acc: 87.21%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 65/100\u001b[0m\n",
      "Train Loss: 0.65\t|\tTrain Acc: 82.13%\n",
      "Val Loss: 0.51\t|\tVal Acc: 87.19%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 66/100\u001b[0m\n",
      "Train Loss: 0.72\t|\tTrain Acc: 79.98%\n",
      "Val Loss: 0.46\t|\tVal Acc: 88.13%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 67/100\u001b[0m\n",
      "Train Loss: 0.66\t|\tTrain Acc: 81.98%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.30%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 68/100\u001b[0m\n",
      "Train Loss: 0.69\t|\tTrain Acc: 80.99%\n",
      "Val Loss: 0.44\t|\tVal Acc: 87.61%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 69/100\u001b[0m\n",
      "Train Loss: 0.69\t|\tTrain Acc: 80.91%\n",
      "Val Loss: 0.47\t|\tVal Acc: 88.02%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 70/100\u001b[0m\n",
      "Train Loss: 0.68\t|\tTrain Acc: 81.37%\n",
      "Val Loss: 0.50\t|\tVal Acc: 87.62%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 71/100\u001b[0m\n",
      "Train Loss: 0.64\t|\tTrain Acc: 83.05%\n",
      "Val Loss: 0.45\t|\tVal Acc: 87.76%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 72/100\u001b[0m\n",
      "Train Loss: 0.65\t|\tTrain Acc: 82.18%\n",
      "Val Loss: 0.46\t|\tVal Acc: 87.90%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 73/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.27%\n",
      "Val Loss: 0.49\t|\tVal Acc: 87.93%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 74/100\u001b[0m\n",
      "Train Loss: 0.71\t|\tTrain Acc: 80.13%\n",
      "Val Loss: 0.46\t|\tVal Acc: 88.00%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 75/100\u001b[0m\n",
      "Train Loss: 0.63\t|\tTrain Acc: 83.23%\n",
      "Val Loss: 0.49\t|\tVal Acc: 87.57%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 76/100\u001b[0m\n",
      "Train Loss: 0.68\t|\tTrain Acc: 81.25%\n",
      "Val Loss: 0.45\t|\tVal Acc: 87.36%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 77/100\u001b[0m\n",
      "Train Loss: 0.66\t|\tTrain Acc: 81.52%\n",
      "Val Loss: 0.46\t|\tVal Acc: 88.22%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 78/100\u001b[0m\n",
      "Train Loss: 0.67\t|\tTrain Acc: 81.73%\n",
      "Val Loss: 0.45\t|\tVal Acc: 87.84%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 79/100\u001b[0m\n",
      "Train Loss: 0.61\t|\tTrain Acc: 83.46%\n",
      "Val Loss: 0.44\t|\tVal Acc: 88.74%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 80/100\u001b[0m\n",
      "Train Loss: 0.62\t|\tTrain Acc: 83.46%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.95%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 81/100\u001b[0m\n",
      "Train Loss: 0.61\t|\tTrain Acc: 83.56%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 83/100\u001b[0m\n",
      "Train Loss: 0.64\t|\tTrain Acc: 82.58%\n",
      "Val Loss: 0.43\t|\tVal Acc: 88.08%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 84/100\u001b[0m\n",
      "Train Loss: 0.57\t|\tTrain Acc: 84.86%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.84%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 85/100\u001b[0m\n",
      "Train Loss: 0.65\t|\tTrain Acc: 82.11%\n",
      "Val Loss: 0.44\t|\tVal Acc: 87.92%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 86/100\u001b[0m\n",
      "Train Loss: 0.64\t|\tTrain Acc: 82.14%\n",
      "Val Loss: 0.45\t|\tVal Acc: 88.77%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 87/100\u001b[0m\n",
      "Train Loss: 0.64\t|\tTrain Acc: 82.79%\n",
      "Val Loss: 0.53\t|\tVal Acc: 87.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\u001b[1;34mEpoch 90/100\u001b[0m\n",
      "Train Loss: 0.73\t|\tTrain Acc: 79.10%\n",
      "Val Loss: 0.46\t|\tVal Acc: 88.31%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 91/100\u001b[0m\n",
      "Train Loss: 0.60\t|\tTrain Acc: 84.32%\n",
      "Val Loss: 0.47\t|\tVal Acc: 88.12%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 92/100\u001b[0m\n",
      "Train Loss: 0.66\t|\tTrain Acc: 81.89%\n",
      "Val Loss: 0.48\t|\tVal Acc: 87.74%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 93/100\u001b[0m\n",
      "Train Loss: 0.60\t|\tTrain Acc: 83.91%\n",
      "Val Loss: 0.47\t|\tVal Acc: 88.24%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 94/100\u001b[0m\n",
      "Train Loss: 0.69\t|\tTrain Acc: 81.10%\n",
      "Val Loss: 0.47\t|\tVal Acc: 87.59%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 95/100\u001b[0m\n",
      "Train Loss: 0.63\t|\tTrain Acc: 82.36%\n",
      "Val Loss: 0.47\t|\tVal Acc: 88.29%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 98/100\u001b[0m\n",
      "Train Loss: 0.63\t|\tTrain Acc: 82.69%\n",
      "Val Loss: 0.43\t|\tVal Acc: 88.31%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 99/100\u001b[0m\n",
      "Train Loss: 0.65\t|\tTrain Acc: 82.75%\n",
      "Val Loss: 0.48\t|\tVal Acc: 88.18%\n",
      "========================================\n",
      "\u001b[1;34mEpoch 100/100\u001b[0m\n",
      "Train Loss: 0.62\t|\tTrain Acc: 83.06%\n",
      "Val Loss: 0.44\t|\tVal Acc: 88.05%\n",
      "========================================\n",
      "Training Completed! ðŸ˜€\n"
     ]
    }
   ],
   "source": [
    "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "train_loss, val_loss = [], []\n",
    "train_acc, val_acc = [], []\n",
    "\n",
    "epoch_bar = tqdm(desc = 'Epoch',\n",
    "                 total = num_epochs, position = 1)\n",
    "train_bar = tqdm(desc = 'Training', total = len(train_loader),\n",
    "                 position = 1, leave = True)\n",
    "val_bar = tqdm(desc = 'Validation', total = len(test_loader),\n",
    "               position = 1, leave = True)\n",
    "\n",
    "print(\"ðŸš€ Training MobileNetV3 - Omni Dimensional Dynamic Convolution ðŸš€\")\n",
    "logging.info(\"ðŸš€ Training MobileNetV3 - Omni Dimensional Dynamic Convolution ðŸš€\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_bar.set_description(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "    mb_v3.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "\n",
    "    total = 0\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        X, y_origin, y_sampled, lam = mixup_data(X, y, device, alpha = 0.4)\n",
    "\n",
    "        # Forward pass\n",
    "        output = mb_v3(X)\n",
    "        # loss = criterion(output, y)\n",
    "        loss = mixup_criterion(criterion, output, y_origin, y_sampled, lam)\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (i + 1)\n",
    "        total_loss += loss_t\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculating the accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        n_correct = (lam * predicted.eq(y_origin.data).cpu().sum().float()\n",
    "                    + (1 - lam) * predicted.eq(y_sampled.data).cpu().sum().float())\n",
    "\n",
    "        acc_t = n_correct / len(predicted) * 100\n",
    "        running_acc += (acc_t - running_acc) / (i + 1)\n",
    "\n",
    "        total_acc += n_correct\n",
    "        total += y.shape[0]\n",
    "\n",
    "\n",
    "        train_bar.set_postfix(loss = running_loss,\n",
    "                              acc = f\"{running_acc:.2f}%\",\n",
    "                              epoch = epoch + 1)\n",
    "        train_bar.update()\n",
    "\n",
    "    current_loss = total_loss / len(train_loader)\n",
    "    current_acc = total_acc / total * 100\n",
    "    train_loss.append(current_loss)\n",
    "    train_acc.append(current_acc)\n",
    "\n",
    "    print(\"========================================\")\n",
    "    print(\"\\033[1;34m\" + f\"Epoch {epoch + 1}/{num_epochs}\" + \"\\033[0m\")\n",
    "    print(f\"Train Loss: {current_loss:.2f}\\t|\\tTrain Acc: {current_acc:.2f}%\")\n",
    "\n",
    "    logging.info(\"========================================\")\n",
    "    logging.info(\"\\033[1;34m\" + f\"Epoch {epoch + 1}/{num_epochs}\" + \"\\033[0m\")\n",
    "    logging.info(f\"Train Loss: {current_loss:.2f}  -   Train Acc: {current_acc:.2f}%\")\n",
    "\n",
    "\n",
    "    # Eval trÃªn valid set\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "\n",
    "    total = 0\n",
    "    mb_v3.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(test_loader):\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Forward pass\n",
    "            output = mb_v3(X)\n",
    "\n",
    "            # Calculate Loss\n",
    "            loss = criterion(output, y)\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (i + 1)\n",
    "            total_loss += loss_t\n",
    "\n",
    "            # Calculate Accuracies\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            n_correct = (predicted == y).sum().item()\n",
    "            acc_t = n_correct / len(predicted) * 100\n",
    "            running_acc += (acc_t - running_acc) / (i + 1)\n",
    "            total_acc += n_correct\n",
    "\n",
    "            total += y.shape[0]\n",
    "\n",
    "            val_bar.set_postfix(loss = running_loss,\n",
    "                                acc = f\"{running_acc:.2f}%\",\n",
    "                                epoch = epoch + 1)\n",
    "            val_bar.update()\n",
    "\n",
    "    current_loss = total_loss / len(test_loader)\n",
    "    current_acc = total_acc / total * 100\n",
    "\n",
    "    val_loss.append(current_loss)\n",
    "    val_acc.append(current_acc)\n",
    "\n",
    "    print(f\"Val Loss: {current_loss:.2f}\\t|\\tVal Acc: {current_acc:.2f}%\")\n",
    "    logging.info(f\"Val Loss: {current_loss:.2f}  -  Val Acc: {current_acc:.2f}%\")\n",
    "\n",
    "    train_bar.n = 0\n",
    "    val_bar.n = 0\n",
    "    epoch_bar.update()\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"Training Completed! ðŸ˜€\")\n",
    "logging.info(\"========================================\")\n",
    "logging.info(\"Training Completed! ðŸ˜€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b9d75f8-6d50-40a6-9a67-3cf70b721017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c803bf8a-7ef8-446a-8db6-bec6f290f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.7.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m loss_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/plot/loss_fig.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m acc_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/plot/acc_fig.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mplot_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m plt_accuracy(train_acc, val_acc, acc_path)\n",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m, in \u001b[0;36mplot_loss\u001b[0;34m(train_loss, val_loss, loss_fig)\u001b[0m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(num_epochs), train_loss)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss Value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:3575\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!sudo pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.path.exists(\"/plot\"):\n",
    "    os.makedirs(\"/plot\")\n",
    "    print(\"Creating a new directory\")\n",
    "\n",
    "def plot_loss(train_loss, val_loss, loss_fig):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(range(num_epochs), train_loss)\n",
    "    plt.plot(range(num_epochs), val_loss)\n",
    "\n",
    "    plt.xlabel(\"Num Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    \n",
    "    plt.savefig(train_fig)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(train_acc, val_acc, acc_fig):\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(range(num_epochs), train_acc)\n",
    "    plt.plot(range(num_epochs), val_acc)\n",
    "\n",
    "    plt.xlabel(\"Num Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    \n",
    "    plt.savefig(acc_fig)\n",
    "    plt.show()\n",
    "\n",
    "loss_path = \"/plot/loss_fig.png\"\n",
    "acc_path = \"/plot/acc_fig.png\"\n",
    "\n",
    "plot_loss(train_loss, val_loss, loss_path)\n",
    "plt_accuracy(train_acc, val_acc, acc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3c723-5c6c-4560-acf0-219fafad9609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
